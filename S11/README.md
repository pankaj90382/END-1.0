# Session 11 Language Translation using Seq2Seq Multiple Attention Mechanism

## Objective

    
## Refrences
 - [Attention Mechanism](https://blog.floydhub.com/attention-mechanism/)
 - [Attention Mechanism Code](https://github.com/spro/practical-pytorch/tree/master/seq2seq-translation)
    
