# Session 9 NLP Evaluation Metrics

## Objective
1.  Implement the following metrics (either on separate models or same, your choice):
    1.  Recall, Precision, and F1 Score
    2.  BLEU
    3.  Perplexity (explain whether you are using bigram, trigram, or something else, what does your PPL score represent?)
    4.  BERTScore (here are  [1 (Links to an external site.)](https://colab.research.google.com/drive/1kpL8Y_AnUUiCxFjhxSrxCsc6-sDMNb_Q)  [2 (Links to an external site.)](https://huggingface.co/metrics/bertscore)  examples)


## Solution

### Text Classification Model and Evaluation
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/pankaj90382/END-1.0/blob/main/S9/END2_LSTM.ipynb)


### Language Translation Model and Evaluation
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/pankaj90382/END-1.0/blob/main/S9/4%20-%20Packed%20Padded%20Sequences%2C%20Masking%2C%20Inference%20and%20BLEU.ipynb)

