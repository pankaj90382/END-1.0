{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Exercises.ipynb","provenance":[{"file_id":"1_xTwO0scFxxnHtuYoNqS_XrTc8XmWU9S","timestamp":1625047296314}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"2VaVIQPawdbU"},"source":["from torchtext.datasets import AG_NEWS"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vBvZyNEAwtgf","executionInfo":{"status":"ok","timestamp":1624550638300,"user_tz":-330,"elapsed":5495,"user":{"displayName":"The Admin","photoUrl":"","userId":"02008525212197398114"}},"outputId":"c056ccb0-9ab1-4bb5-fb86-5d2a77115f92"},"source":["train_iter = AG_NEWS(split='train')\n","next(train_iter)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train.csv: 29.5MB [00:00, 78.5MB/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["(3,\n"," \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TrC7Ywp0w2j9","executionInfo":{"status":"ok","timestamp":1624550778452,"user_tz":-330,"elapsed":6,"user":{"displayName":"The Admin","photoUrl":"","userId":"02008525212197398114"}},"outputId":"0218a6a0-fca6-4ba6-d4ed-aee88a613ea6"},"source":["# or iterate over a loop\n","\n","for (ln, (label, line)) in enumerate(train_iter):\n","  print(label, line)\n","  if ln == 20:\n","    break\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3 Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\which has a reputation for making well-timed and occasionally\\controversial plays in the defense industry, has quietly placed\\its bets on another part of the market.\n","3 Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market next week during the depth of the\\summer doldrums.\n","3 Iraq Halts Oil Exports from Main Southern Pipeline (Reuters) Reuters - Authorities have halted oil export\\flows from the main pipeline in southern Iraq after\\intelligence showed a rebel militia could strike\\infrastructure, an oil official said on Saturday.\n","3 Oil prices soar to all-time record, posing new menace to US economy (AFP) AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.\n","3 Stocks End Up, But Near Year Lows (Reuters) Reuters - Stocks ended slightly higher on Friday\\but stayed near lows for the year as oil prices surged past  #36;46\\a barrel, offsetting a positive outlook from computer maker\\Dell Inc. (DELL.O)\n","3 Money Funds Fell in Latest Week (AP) AP - Assets of the nation's retail money market mutual funds fell by  #36;1.17 billion in the latest week to  #36;849.98 trillion, the Investment Company Institute said Thursday.\n","3 Fed minutes show dissent over inflation (USATODAY.com) USATODAY.com - Retail sales bounced back a bit in July, and new claims for jobless benefits fell last week, the government said Thursday, indicating the economy is improving from a midsummer slump.\n","3 Safety Net (Forbes.com) Forbes.com - After earning a PH.D. in Sociology, Danny Bazil Riley started to work as the general manager at a commercial real estate firm at an annual base salary of  #36;70,000. Soon after, a financial planner stopped by his desk to drop off brochures about insurance benefits available through his employer. But, at 32, \"buying insurance was the furthest thing from my mind,\" says Riley.\n","3 Wall St. Bears Claw Back Into the Black  NEW YORK (Reuters) - Short-sellers, Wall Street's dwindling  band of ultra-cynics, are seeing green again.\n","3 Oil and Economy Cloud Stocks' Outlook  NEW YORK (Reuters) - Soaring crude prices plus worries  about the economy and the outlook for earnings are expected to  hang over the stock market next week during the depth of the  summer doldrums.\n","3 No Need for OPEC to Pump More-Iran Gov  TEHRAN (Reuters) - OPEC can do nothing to douse scorching  oil prices when markets are already oversupplied by 2.8 million  barrels per day (bpd) of crude, Iran's OPEC governor said  Saturday, warning that prices could fall sharply.\n","3 Non-OPEC Nations Should Up Output-Purnomo  JAKARTA (Reuters) - Non-OPEC oil exporters should consider  increasing output to cool record crude prices, OPEC President  Purnomo Yusgiantoro said on Sunday.\n","3 Google IPO Auction Off to Rocky Start  WASHINGTON/NEW YORK (Reuters) - The auction for Google  Inc.'s highly anticipated initial public offering got off to a  rocky start on Friday after the Web search company sidestepped  a bullet from U.S. securities regulators.\n","3 Dollar Falls Broadly on Record Trade Gap  NEW YORK (Reuters) - The dollar tumbled broadly on Friday  after data showing a record U.S. trade deficit in June cast  fresh doubts on the economy's recovery and its ability to draw  foreign capital to fund the growing gap.\n","3 Rescuing an Old Saver If you think you may need to help your elderly relatives with their finances, don't be shy about having the money talk -- soon.\n","3 Kids Rule for Back-to-School The purchasing power of kids is a big part of why the back-to-school season has become such a huge marketing phenomenon.\n","3 In a Down Market, Head Toward Value Funds There is little cause for celebration in the stock market these days, but investors in value-focused mutual funds have reason to feel a bit smug -- if only because they've lost less than the folks who stuck with growth.\n","3 US trade deficit swells in June The US trade deficit has exploded 19 to a record \\$55.8bn as oil costs drove imports higher, according to a latest figures.\n","3 Shell 'could be target for Total' Oil giant Shell could be bracing itself for a takeover attempt, possibly from French rival Total, a  press report claims.\n","3 Google IPO faces Playboy slip-up The bidding gets underway for Google's public offering, despite last-minute worries over an interview with its bosses in Playboy magazine.\n","3 Eurozone economy keeps growing Official figures show the 12-nation eurozone economy continues to grow, but there are warnings it may slow down later in the year.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sDP3CqFKxZ7X","executionInfo":{"status":"ok","timestamp":1624550868032,"user_tz":-330,"elapsed":453,"user":{"displayName":"The Admin","photoUrl":"","userId":"02008525212197398114"}},"outputId":"fe85aeff-56f6-4aeb-bb0c-b9c31d19534e"},"source":["# dataloader\n","from torch.utils.data import DataLoader\n","train_iter = AG_NEWS(split='train')\n","dataloader = DataLoader(train_iter, batch_size=8, shuffle=False)\n","\n","next(iter(dataloader))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor([3, 3, 3, 3, 3, 3, 3, 3]),\n"," (\"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\",\n","  'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.',\n","  \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\\\about the economy and the outlook for earnings are expected to\\\\hang over the stock market next week during the depth of the\\\\summer doldrums.\",\n","  'Iraq Halts Oil Exports from Main Southern Pipeline (Reuters) Reuters - Authorities have halted oil export\\\\flows from the main pipeline in southern Iraq after\\\\intelligence showed a rebel militia could strike\\\\infrastructure, an oil official said on Saturday.',\n","  'Oil prices soar to all-time record, posing new menace to US economy (AFP) AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.',\n","  'Stocks End Up, But Near Year Lows (Reuters) Reuters - Stocks ended slightly higher on Friday\\\\but stayed near lows for the year as oil prices surged past  #36;46\\\\a barrel, offsetting a positive outlook from computer maker\\\\Dell Inc. (DELL.O)',\n","  \"Money Funds Fell in Latest Week (AP) AP - Assets of the nation's retail money market mutual funds fell by  #36;1.17 billion in the latest week to  #36;849.98 trillion, the Investment Company Institute said Thursday.\",\n","  'Fed minutes show dissent over inflation (USATODAY.com) USATODAY.com - Retail sales bounced back a bit in July, and new claims for jobless benefits fell last week, the government said Thursday, indicating the economy is improving from a midsummer slump.')]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"7OGbN_YIyHfG"},"source":["Torchtext has revamped the very basic components of the torchtext library, including vocab, word vectors, tokenizer. These are the basic data processing building blocks for a raw text strings. \n","\n","Here is an example for typical NLP data processing with tokenizer and vocabulary. The first step is to build a vocabulary with the raw training dataset. Here we use built in factory function build_vocab_from_iterator which accepts iterator that yield list or iterator of tokens. Users can also pass any special symbols to be added to the vocabulary."]},{"cell_type":"code","metadata":{"id":"4ITqjdsvxrnB"},"source":["from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","tokenizer = get_tokenizer('basic_english')\n","train_iter = AG_NEWS(split='train')\n","\n","def yield_tokens(data_iter):\n","    for _, text in data_iter:\n","        yield tokenizer(text)\n","\n","vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n","vocab.set_default_index(vocab[\"<unk>\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IKhLvaKLzQek","executionInfo":{"status":"ok","timestamp":1624551606459,"user_tz":-330,"elapsed":461,"user":{"displayName":"The Admin","photoUrl":"","userId":"02008525212197398114"}},"outputId":"1db3f46b-13fd-4a6e-9f70-3174590dd6d9"},"source":["vocab(['here', 'is', 'an', 'example', 'theschoolofai'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[475, 21, 30, 5297, 0]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"WEg8TR080r_-"},"source":["Prepare the text processing pipeline with the tokenizer and vocabulary. The text and label pipelines will be used to process the raw data strings from the dataset iterators."]},{"cell_type":"code","metadata":{"id":"KPIlKV9P0gi3"},"source":["text_pipeline = lambda x: vocab(tokenizer(x))\n","label_pipeline = lambda x: int(x) - 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d1fpaYln0zZH","executionInfo":{"status":"ok","timestamp":1624551676867,"user_tz":-330,"elapsed":483,"user":{"displayName":"The Admin","photoUrl":"","userId":"02008525212197398114"}},"outputId":"c6e9b21e-a0f9-4dc4-983c-69b06e643888"},"source":["text_pipeline('here is the an example')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[475, 21, 2, 30, 5297]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OLAt2Kyi01cZ","executionInfo":{"status":"ok","timestamp":1624551697517,"user_tz":-330,"elapsed":482,"user":{"displayName":"The Admin","photoUrl":"","userId":"02008525212197398114"}},"outputId":"9cbabdbb-48c1-4065-c3c4-3e2da2ff4d53"},"source":["label_pipeline('10')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"TcLXuyuD1T4X"},"source":["## Generate data batch and iterator\n","\n","torch.utils.data.DataLoader is recommended for PyTorch users. It works with a map-style dataset that implements the getitem() and len() protocols, and represents a map from indices/keys to data samples. It also works with an iterable dataset with the shuffle argument of False.\n","\n","Before sending to the model, collate_fn function works on a batch of samples generated from DataLoader. The input to collate_fn is a batch of data with the batch size in DataLoader, and collate_fn processes them according to the data processing pipelines declared previously. Pay attention here and make sure that collate_fn is declared as a top level def. This ensures that the function is available in each worker."]},{"cell_type":"code","metadata":{"id":"JbhW4lz606fh"},"source":["from torch.utils.data import DataLoader\n","import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def collate_fn(batch):\n","    src_batch, tgt_batch = [], []\n","    for src_sample, tgt_sample in batch:\n","        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n","        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n","\n","    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n","    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n","    return src_batch, tgt_batch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wpays4p95I_z"},"source":["EmbeddingBag is a useful feature to consume sparse ids and produce embeddings. Later we are going to see examples where the text entries in the original batch input will be backed into a list and concatenated as a single tensor for the input of nn.EmbeddingBag.\n","\n","It is doing two things. The first step is to create an embedding and the second step is to reduce (sum/mean/max, according to the \"mode\" argument) the embedding output across dimension 0. So this is equivalent to torch.nn.functional.embedding, followed by torch.sum/mean/max. However, the conceptual two step process does not reflect how it's actually implemented. Since embedding_bag does not need to return the intermediate result, it doesn't actually generate a Tensor object for the embedding. It just goes straight to computing the reduction, pulling in the appropriate data from the weight argument according to the indices in the input argument. Avoiding the creation of the embedding Tensor allows for better performance"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cmBi1Nlb2lXr","executionInfo":{"status":"ok","timestamp":1624552834524,"user_tz":-330,"elapsed":1167,"user":{"displayName":"The Admin","photoUrl":"","userId":"02008525212197398114"}},"outputId":"6f396f85-0d21-4529-d295-aeb29900aba2"},"source":["weight = torch.randn(3, 4)\n","weight"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.3008, -1.1174,  1.1937, -0.8687],\n","        [-0.1184,  1.2760, -0.8432, -0.3980],\n","        [ 0.3280,  0.6792, -0.6592,  0.7455]])"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b1OmVDGp5N_f","executionInfo":{"status":"ok","timestamp":1624552853445,"user_tz":-330,"elapsed":1392,"user":{"displayName":"The Admin","photoUrl":"","userId":"02008525212197398114"}},"outputId":"3160232c-c116-447a-8312-9b946646a22c"},"source":["indices = torch.tensor([2, 1])\n","indices"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2, 1])"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wmI3jesm5UEh","executionInfo":{"status":"ok","timestamp":1624552893661,"user_tz":-330,"elapsed":478,"user":{"displayName":"The Admin","photoUrl":"","userId":"02008525212197398114"}},"outputId":"ea24f420-f059-4e9f-8520-3772f2a96d65"},"source":["embedding_dwork = torch.nn.functional.embedding(indices, weight)\n","embedding_dwork"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.3280,  0.6792, -0.6592,  0.7455],\n","        [-0.1184,  1.2760, -0.8432, -0.3980]])"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZLPLNGmj5ehJ","executionInfo":{"status":"ok","timestamp":1624552927984,"user_tz":-330,"elapsed":1725,"user":{"displayName":"The Admin","photoUrl":"","userId":"02008525212197398114"}},"outputId":"babf2cc9-ee5f-4af5-ad9b-3a3cd978ab36"},"source":["embedding_dwork_mean = embedding_dwork.mean(dim=0, keepdim=True)\n","embedding_dwork_mean"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.1048,  0.9776, -0.7512,  0.1737]])"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"86xXxo575mlx","executionInfo":{"status":"ok","timestamp":1624552973524,"user_tz":-330,"elapsed":471,"user":{"displayName":"The Admin","photoUrl":"","userId":"02008525212197398114"}},"outputId":"ea28bdd7-7a4a-485a-c07e-fa2b661f5d5c"},"source":["embedding_bag = torch.nn.functional.embedding_bag(indices, weight, torch.tensor([0]), mode='mean')\n","embedding_bag"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.1048,  0.9776, -0.7512,  0.1737]])"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"eG9ExKRG6z2M"},"source":["In this example, the text entries in the original data batch input are packed into a list and concatenated as a single tensor for the input of nn.EmbeddingBag. The offset is a tensor of delimiters to represent the beginning index of the individual sequence in the text tensor. Label is a tensor saving the labels of individual text entries."]},{"cell_type":"code","metadata":{"id":"2Fo_Yp1I5tQ_"},"source":["def collate_batch(batch):\n","    label_list, text_list, offsets = [], [], [0]\n","    for (_label, _text) in batch:\n","         label_list.append(label_pipeline(_label))\n","         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n","         text_list.append(processed_text)\n","         offsets.append(processed_text.size(0))\n","    label_list = torch.tensor(label_list, dtype=torch.int64)\n","    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n","    text_list = torch.cat(text_list)\n","    return label_list.to(device), text_list.to(device), offsets.to(device)    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dQYlLbzq629a"},"source":["train_iter = AG_NEWS(split='train')\n","dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vy1IdVAv7Xod"},"source":["The model is composed of the nn.EmbeddingBag <https://pytorch.org/docs/stable/nn.html?highlight=embeddingbag#torch.nn.EmbeddingBag>__ layer plus a linear layer for the classification purpose. nn.EmbeddingBag with the default mode of \"mean\" computes the mean value of a “bag” of embeddings. Although the text entries here have different lengths, nn.EmbeddingBag module requires no padding here since the text lengths are saved in offsets.\n","\n","Additionally, since nn.EmbeddingBag accumulates the average across the embeddings on the fly, nn.EmbeddingBag can enhance the performance and memory efficiency to process a sequence of tensors."]},{"cell_type":"code","metadata":{"id":"IWiF5WDj7VVK"},"source":["from torch import nn\n","\n","class TextClassificationModel(nn.Module):\n","\n","    def __init__(self, vocab_size, embed_dim, num_class):\n","        super(TextClassificationModel, self).__init__()\n","        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n","        self.fc = nn.Linear(embed_dim, num_class)\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        initrange = 0.5\n","        self.embedding.weight.data.uniform_(-initrange, initrange)\n","        self.fc.weight.data.uniform_(-initrange, initrange)\n","        self.fc.bias.data.zero_()\n","\n","    def forward(self, text, offsets):\n","        embedded = self.embedding(text, offsets)\n","        return self.fc(embedded)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HQYxfdZc7eWm"},"source":["The AG_NEWS dataset has four labels and therefore the number of classes is four.\n","\n","::\n","\n","1 : World 2 : Sports 3 : Business 4 : Sci/Tec\n","\n","We build a model with the embedding dimension of 64. The vocab size is equal to the length of the vocabulary instance. The number of classes is equal to the number of labels,"]},{"cell_type":"code","metadata":{"id":"_WCp2e_C7Z5S"},"source":["train_iter = AG_NEWS(split='train')\n","num_class = len(set([label for (label, text) in train_iter]))\n","vocab_size = len(vocab)\n","emsize = 64\n","model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cRLyvS-f7f-D"},"source":["import time\n","\n","def train(dataloader):\n","    model.train()\n","    total_acc, total_count = 0, 0\n","    log_interval = 500\n","    start_time = time.time()\n","\n","    for idx, (label, text, offsets) in enumerate(dataloader):\n","        optimizer.zero_grad()\n","        predited_label = model(text, offsets)\n","        loss = criterion(predited_label, label)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n","        optimizer.step()\n","        total_acc += (predited_label.argmax(1) == label).sum().item()\n","        total_count += label.size(0)\n","        if idx % log_interval == 0 and idx > 0:\n","            elapsed = time.time() - start_time\n","            print('| epoch {:3d} | {:5d}/{:5d} batches '\n","                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n","                                              total_acc/total_count))\n","            total_acc, total_count = 0, 0\n","            start_time = time.time()\n","\n","def evaluate(dataloader):\n","    model.eval()\n","    total_acc, total_count = 0, 0\n","\n","    with torch.no_grad():\n","        for idx, (label, text, offsets) in enumerate(dataloader):\n","            predited_label = model(text, offsets)\n","            loss = criterion(predited_label, label)\n","            total_acc += (predited_label.argmax(1) == label).sum().item()\n","            total_count += label.size(0)\n","    return total_acc/total_count"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GtzEbdi17rDd"},"source":["Split the dataset and run the model\n","Since the original AG_NEWS has no valid dataset, we split the training dataset into train/valid sets with a split ratio of 0.95 (train) and 0.05 (valid). Here we use torch.utils.data.dataset.random_split <https://pytorch.org/docs/stable/data.html?highlight=random_split#torch.utils.data.random_split>__ function in PyTorch core library.\n","\n","CrossEntropyLoss <https://pytorch.org/docs/stable/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss>__ criterion combines nn.LogSoftmax() and nn.NLLLoss() in a single class. It is useful when training a classification problem with C classes. SGD <https://pytorch.org/docs/stable/_modules/torch/optim/sgd.html>__ implements stochastic gradient descent method as the optimizer. The initial learning rate is set to 5.0. StepLR <https://pytorch.org/docs/master/_modules/torch/optim/lr_scheduler.html#StepLR>__ is used here to adjust the learning rate through epochs."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kkoEyB2b7itr","executionInfo":{"status":"ok","timestamp":1624553581974,"user_tz":-330,"elapsed":132736,"user":{"displayName":"The Admin","photoUrl":"","userId":"02008525212197398114"}},"outputId":"c839f0ca-92af-4d9f-85e9-090dfb462987"},"source":["from torch.utils.data.dataset import random_split\n","from torchtext.data.functional import to_map_style_dataset\n","# Hyperparameters\n","EPOCHS = 10 # epoch\n","LR = 5  # learning rate\n","BATCH_SIZE = 64 # batch size for training\n","  \n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n","total_accu = None\n","train_iter, test_iter = AG_NEWS()\n","train_dataset = to_map_style_dataset(train_iter)\n","test_dataset = to_map_style_dataset(test_iter)\n","num_train = int(len(train_dataset) * 0.95)\n","split_train_, split_valid_ = \\\n","    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n","\n","train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n","                              shuffle=True, collate_fn=collate_batch)\n","valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n","                              shuffle=True, collate_fn=collate_batch)\n","test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n","                             shuffle=True, collate_fn=collate_batch)\n","\n","for epoch in range(1, EPOCHS + 1):\n","    epoch_start_time = time.time()\n","    train(train_dataloader)\n","    accu_val = evaluate(valid_dataloader)\n","    if total_accu is not None and total_accu > accu_val:\n","      scheduler.step()\n","    else:\n","       total_accu = accu_val\n","    print('-' * 59)\n","    print('| end of epoch {:3d} | time: {:5.2f}s | '\n","          'valid accuracy {:8.3f} '.format(epoch,\n","                                           time.time() - epoch_start_time,\n","                                           accu_val))\n","    print('-' * 59)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test.csv: 1.86MB [00:00, 32.9MB/s]                  \n"],"name":"stderr"},{"output_type":"stream","text":["| epoch   1 |   500/ 1782 batches | accuracy    0.687\n","| epoch   1 |  1000/ 1782 batches | accuracy    0.856\n","| epoch   1 |  1500/ 1782 batches | accuracy    0.877\n","-----------------------------------------------------------\n","| end of epoch   1 | time: 13.51s | valid accuracy    0.900 \n","-----------------------------------------------------------\n","| epoch   2 |   500/ 1782 batches | accuracy    0.900\n","| epoch   2 |  1000/ 1782 batches | accuracy    0.898\n","| epoch   2 |  1500/ 1782 batches | accuracy    0.901\n","-----------------------------------------------------------\n","| end of epoch   2 | time: 13.20s | valid accuracy    0.907 \n","-----------------------------------------------------------\n","| epoch   3 |   500/ 1782 batches | accuracy    0.915\n","| epoch   3 |  1000/ 1782 batches | accuracy    0.916\n","| epoch   3 |  1500/ 1782 batches | accuracy    0.914\n","-----------------------------------------------------------\n","| end of epoch   3 | time: 13.20s | valid accuracy    0.913 \n","-----------------------------------------------------------\n","| epoch   4 |   500/ 1782 batches | accuracy    0.925\n","| epoch   4 |  1000/ 1782 batches | accuracy    0.924\n","| epoch   4 |  1500/ 1782 batches | accuracy    0.922\n","-----------------------------------------------------------\n","| end of epoch   4 | time: 12.91s | valid accuracy    0.916 \n","-----------------------------------------------------------\n","| epoch   5 |   500/ 1782 batches | accuracy    0.932\n","| epoch   5 |  1000/ 1782 batches | accuracy    0.929\n","| epoch   5 |  1500/ 1782 batches | accuracy    0.927\n","-----------------------------------------------------------\n","| end of epoch   5 | time: 13.13s | valid accuracy    0.910 \n","-----------------------------------------------------------\n","| epoch   6 |   500/ 1782 batches | accuracy    0.942\n","| epoch   6 |  1000/ 1782 batches | accuracy    0.943\n","| epoch   6 |  1500/ 1782 batches | accuracy    0.943\n","-----------------------------------------------------------\n","| end of epoch   6 | time: 13.13s | valid accuracy    0.918 \n","-----------------------------------------------------------\n","| epoch   7 |   500/ 1782 batches | accuracy    0.945\n","| epoch   7 |  1000/ 1782 batches | accuracy    0.943\n","| epoch   7 |  1500/ 1782 batches | accuracy    0.946\n","-----------------------------------------------------------\n","| end of epoch   7 | time: 13.07s | valid accuracy    0.918 \n","-----------------------------------------------------------\n","| epoch   8 |   500/ 1782 batches | accuracy    0.946\n","| epoch   8 |  1000/ 1782 batches | accuracy    0.945\n","| epoch   8 |  1500/ 1782 batches | accuracy    0.947\n","-----------------------------------------------------------\n","| end of epoch   8 | time: 12.76s | valid accuracy    0.920 \n","-----------------------------------------------------------\n","| epoch   9 |   500/ 1782 batches | accuracy    0.945\n","| epoch   9 |  1000/ 1782 batches | accuracy    0.947\n","| epoch   9 |  1500/ 1782 batches | accuracy    0.945\n","-----------------------------------------------------------\n","| end of epoch   9 | time: 12.84s | valid accuracy    0.919 \n","-----------------------------------------------------------\n","| epoch  10 |   500/ 1782 batches | accuracy    0.944\n","| epoch  10 |  1000/ 1782 batches | accuracy    0.946\n","| epoch  10 |  1500/ 1782 batches | accuracy    0.947\n","-----------------------------------------------------------\n","| end of epoch  10 | time: 12.92s | valid accuracy    0.919 \n","-----------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gbksWIvf7mQ_","executionInfo":{"status":"ok","timestamp":1624553621996,"user_tz":-330,"elapsed":525,"user":{"displayName":"The Admin","photoUrl":"","userId":"02008525212197398114"}},"outputId":"96658618-a018-4605-bda3-9958db262127"},"source":["print('Checking the results of test dataset.')\n","accu_test = evaluate(test_dataloader)\n","print('test accuracy {:8.3f}'.format(accu_test))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Checking the results of test dataset.\n","test accuracy    0.903\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OYU4VwXe74Rw"},"source":["Test on a random news\n","Use the best model so far and test a golf news."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xyr280I774uR","executionInfo":{"status":"ok","timestamp":1624553626096,"user_tz":-330,"elapsed":506,"user":{"displayName":"The Admin","photoUrl":"","userId":"02008525212197398114"}},"outputId":"877053ae-3de3-43f4-bfb0-cc7068e14925"},"source":["ag_news_label = {1: \"World\",\n","                 2: \"Sports\",\n","                 3: \"Business\",\n","                 4: \"Sci/Tec\"}\n","\n","def predict(text, text_pipeline):\n","    with torch.no_grad():\n","        text = torch.tensor(text_pipeline(text))\n","        output = model(text, torch.tensor([0]))\n","        return output.argmax(1).item() + 1\n","\n","ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n","    enduring the season’s worst weather conditions on Sunday at The \\\n","    Open on his way to a closing 75 at Royal Portrush, which \\\n","    considering the wind and the rain was a respectable showing. \\\n","    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n","    was another story. With temperatures in the mid-80s and hardly any \\\n","    wind, the Spaniard was 13 strokes better in a flawless round. \\\n","    Thanks to his best putting performance on the PGA Tour, Rahm \\\n","    finished with an 8-under 62 for a three-stroke lead, which \\\n","    was even more impressive considering he’d never played the \\\n","    front nine at TPC Southwind.\"\n","\n","model = model.to(\"cpu\")\n","\n","print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, text_pipeline)])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["This is a Sports news\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_Y6OjztL8RU-"},"source":[""],"execution_count":null,"outputs":[]}]}