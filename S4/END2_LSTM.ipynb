{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"END2_LSTM.ipynb","provenance":[{"file_id":"1-xwX32O0WYOqcCROJnnJiSdzScPCudAM","timestamp":1622096280486}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zDephuo-zRx-","executionInfo":{"status":"ok","timestamp":1622105359505,"user_tz":-330,"elapsed":619,"user":{"displayName":"Sachin Salman","photoUrl":"","userId":"05425883655044061385"}},"outputId":"d6c010d8-ffff-4dfa-9ca3-384ddf0656a0"},"source":["! nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Thu May 27 08:49:17 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   56C    P0    25W /  75W |      0MiB /  7611MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4SPhj6gnAnT2","executionInfo":{"status":"ok","timestamp":1622105361865,"user_tz":-330,"elapsed":1889,"user":{"displayName":"Sachin Salman","photoUrl":"","userId":"05425883655044061385"}}},"source":["import torch\n","from torchtext.legacy import data\n","\n","SEED = 1234\n","\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","TEXT = data.Field(tokenize = 'spacy',\n","                  tokenizer_language = 'en_core_web_sm')\n","LABEL = data.LabelField(dtype = torch.float)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"lwn4oStE6PzV"},"source":["from torchtext.legacy import datasets\n","\n","train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5DLJ86m56Xdn"},"source":["print(f'Number of training examples: {len(train_data)}')\n","print(f'Number of testing examples: {len(test_data)}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iXTWwqXA6rP2"},"source":["print(vars(train_data.examples[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3HMVqiZd6tR0"},"source":["import random\n","\n","train_data, valid_data = train_data.split(random_state = random.seed(SEED))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uOeQ6KpP7M-0"},"source":["print(f'Number of training examples: {len(train_data)}')\n","print(f'Number of validation examples: {len(valid_data)}')\n","print(f'Number of testing examples: {len(test_data)}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KixkM1jQ7TB-"},"source":["MAX_VOCAB_SIZE = 25_000\n","\n","TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n","LABEL.build_vocab(train_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hD4SFKnc7g0D"},"source":["print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n","print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttKvFTCQ7isK"},"source":["print(TEXT.vocab.freqs.most_common(20))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fZXIsIV47mlI"},"source":["print(TEXT.vocab.itos[:10])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vmbx3T9-7x4g"},"source":["print(LABEL.vocab.stoi)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B3gBfP6mEJ_0"},"source":["BATCH_SIZE = 128\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size = BATCH_SIZE,\n","    sort_within_batch = True,\n","    device = device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LPY_p6j-z5GZ"},"source":["print('Train')\n","for batch in train_iterator:\n","    print(f'Text matrix size: {batch.text[0].size()}')\n","    print(f'Target vector size: {batch.label.size()}')\n","    break\n","    \n","print('\\nValid:')\n","for batch in valid_iterator:\n","    print(f'Text matrix size: {batch.text[0].size()}')\n","    print(f'Target vector size: {batch.label.size()}')\n","    break\n","    \n","print('\\nTest:')\n","for batch in test_iterator:\n","    print(f'Text matrix size: {batch.text[0].size()}')\n","    print(f'Target vector size: {batch.label.size()}')\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E2ZQQV1-ELZf"},"source":["import torch.nn as nn\n","\n","class LSTM(nn.Module):\n","    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n","        \n","        super().__init__()\n","        \n","        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx )\n","        \n","        self.LSTM = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout, bidirectional=bidirectional)\n","        \n","        self.fc = nn.Linear(hidden_dim , output_dim)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, text, text_lengths):\n","\n","        #text = [sent len, batch size]\n","        \n","        embedded = self.dropout(self.embedding(text))\n","        \n","        #embedded = [sent len, batch size, emb dim]\n","        \n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'))\n","\n","        output, hidden = self.LSTM(packed_embedded)\n","        \n","        #output = [sent len, batch size, hid dim]\n","        #hidden = [1, batch size, hid dim]\n","        \n","        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n","        \n","        return self.fc(hidden.squeeze(0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iiCQiEVTsWS3"},"source":["print('INPUT_DIM = ',len(TEXT.vocab))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lkHS_qYc42Vr"},"source":["print(TEXT.vocab.stoi[TEXT.pad_token])\n","print(TEXT.pad_token)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x0_X5kSwENad"},"source":["\n","INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 128\n","HIDDEN_DIM = 256\n","OUTPUT_DIM = 1\n","N_LAYERS = 2\n","BIDIRECTIONAL = True\n","DROPOUT = 0.5\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","model = LSTM(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VdGb8dKBEO2x"},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AAeEtXiJEQCj"},"source":["import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Utp4-qAERRG"},"source":["criterion = nn.BCEWithLogitsLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PyAXf58FESdL"},"source":["model = model.to(device)\n","criterion = criterion.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w4yNiGXQETh9"},"source":["def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum() / len(correct)\n","    return acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N1iGJW1wEUrL"},"source":["def train(model, iterator, optimizer, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.train()\n","    \n","    for batch in iterator:\n","        \n","        optimizer.zero_grad()\n","                \n","        predictions = model(batch.text).squeeze(1)\n","        \n","        loss = criterion(predictions, batch.label)\n","        \n","        acc = binary_accuracy(predictions, batch.label)\n","        \n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HNQxQS3tEWUW"},"source":["def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","\n","            predictions = model(batch.text).squeeze(1)\n","            \n","            loss = criterion(predictions, batch.label)\n","            \n","            acc = binary_accuracy(predictions, batch.label)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DVM8MtV6EYIw"},"source":["import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yJ5KZmM4EZXW"},"source":["N_EPOCHS = 30\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut1-model.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qIiKAJMaEbKO"},"source":["model.load_state_dict(torch.load('tut1-model.pt'))\n","\n","test_loss, test_acc = evaluate(model, test_iterator, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G024NssCEcj0"},"source":[""],"execution_count":null,"outputs":[]}]}